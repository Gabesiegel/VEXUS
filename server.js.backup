import express from 'express';
import { v1, helpers } from '@google-cloud/aiplatform';
import { GoogleAuth, JWT } from 'google-auth-library';
import { SecretManagerServiceClient } from '@google-cloud/secret-manager';
import { Storage } from '@google-cloud/storage';
import path from 'path';
import { fileURLToPath } from 'url';
import { promises as fs } from 'fs';
import {spawn} from 'child_process';
import cors from 'cors';
import mongoose from 'mongoose';
import bodyParser from 'body-parser';
import { Firestore } from '@google-cloud/firestore';
import multer from 'multer';
import http from 'http';
import fetch from 'node-fetch';
import { PredictionServiceClient } from '@google-cloud/aiplatform';

// ES modules dirname setup
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

///////////////////////////////////////////////////////////////////////////////
// 1) Configuration Setup
///////////////////////////////////////////////////////////////////////////////

const CONFIG = {
    projectId: "plucky-weaver-450819-k7",
    projectNumber: "456295042668",
    location: "us-central1",
    endpointIds: {
        hepatic: process.env.HEPATIC_ENDPOINT_ID || "8159951878260523008",  // VExUS - Hepatic Vein
        portal: process.env.PORTAL_ENDPOINT_ID || "2970410926785691648",    // VExUS - Portal Vein
        renal: process.env.RENAL_ENDPOINT_ID || "1148704877514326016"      // VExUS - Renal Vein
    },
    onDemandEndpointService: process.env.ON_DEMAND_ENDPOINT_SERVICE || "https://endpoints-on-demand-456295042668.us-central1.run.app",
    lastUpdated: new Date().toISOString(),
    developer: 'Gabesiegel',
    bucketName: "vexus-ai-images-plucky-weaver-450819-k7-20250223131511"
}; // Each vein type uses its own specific endpoint

// Initialize Cloud Storage client
const storage = new Storage();
const bucket = storage.bucket(CONFIG.bucketName);

// Initialize Firestore
const firestore = new Firestore({
    projectId: CONFIG.projectId,
});

// Configure multer for memory storage (no temp files)
const upload = multer({ 
    storage: multer.memoryStorage(),
    limits: {
        fileSize: 5 * 1024 * 1024 // 5MB limit
    }
});

// Function to ensure required directories exist in the bucket
async function ensureStorageDirectories() {
    try {
        const requiredDirs = ['images', 'results'];
        
        for (const dir of requiredDirs) {
            const file = bucket.file(`${dir}/.keep`);
            
            // Check if directory exists (checking for .keep file)
            const [exists] = await file.exists();
            
            if (!exists) {
                console.log(`Creating directory: ${dir}/`);
                await file.save('', { contentType: 'text/plain' });
                console.log(`Created directory marker: ${dir}/.keep`);
            } else {
                console.log(`Directory already exists: ${dir}/`);
            }
        }
        
        console.log('Storage directories verified');
    } catch (error) {
        console.error('Error ensuring storage directories:', error);
        // Don't throw an error to allow server to continue starting
    }
}

// Function to upload image to Cloud Storage
async function uploadImage(base64Image, imageType = 'unknown') {
    try {
        let base64Data = base64Image;
        
        // Handle data URL format if provided
        if (base64Image.includes('data:')) {
            const dataURLParts = base64Image.split(',');
            if (dataURLParts.length !== 2) {
                throw new Error('Invalid data URL format');
            }
            imageType = dataURLParts[0].match(/:(.*?);/)[1];
            base64Data = dataURLParts[1];
        }

        const buffer = Buffer.from(base64Data, 'base64');
        const extension = imageType.split('/')[1] || 'jpg';
        const timestamp = Date.now();
        const filename = `image_${timestamp}.${extension}`;
        const file = bucket.file(`images/${filename}`);

        console.log(`Uploading image: ${filename}`);
        await fs.appendFile('server.log', `[${new Date().toISOString()}] Uploading image: ${filename}\n`);

        try {
            await file.save(buffer, {
                metadata: {
                    contentType: imageType
                }
            });
        } catch (uploadError) {
            console.error('Error during file.save:', uploadError);
            await fs.appendFile('server.log', `[${new Date().toISOString()}] Error during file.save: ${uploadError}\n`);
            throw uploadError;
        }
        
        const publicUrl = `https://storage.googleapis.com/${CONFIG.bucketName}/images/${filename}`;
        const gcsPath = `gs://${CONFIG.bucketName}/images/${filename}`;
        
        console.log("Image uploaded to:", gcsPath);
        await fs.appendFile('server.log', `[${new Date().toISOString()}] Image uploaded to: ${gcsPath}\n`);
        
        return {
            filename,
            gcsPath,
            publicUrl,
            timestamp
        };
    } catch (error) {
        console.error('Error uploading image:', error);
        await fs.appendFile('server.log', `[${new Date().toISOString()}] Error in uploadImage function: ${error}\n`);
        throw error;
    }
}

// Function to store prediction results in Cloud Storage
async function storePredictionResults(imageInfo, predictions, type = 'unknown') {
    try {
        const resultData = {
            imageInfo,
            predictions,
            type,
            timestamp: new Date().toISOString()
        };
        
        const filename = `results/${imageInfo.filename.replace(/\.[^/.]+$/, '')}_results.json`;
        const file = bucket.file(filename);
        
        await file.save(JSON.stringify(resultData, null, 2), {
            metadata: {
                contentType: 'application/json'
            }
        });
        
        const gcsPath = `gs://${CONFIG.bucketName}/${filename}`;
        console.log("Prediction results stored at:", gcsPath);
        await fs.appendFile('server.log', `[${new Date().toISOString()}] Prediction results stored at: ${gcsPath}\n`);
        
        return gcsPath;
    } catch (error) {
        console.error('Error storing prediction results:', error);
        await fs.appendFile('server.log', `[${new Date().toISOString()}] Error storing prediction results: ${error}\n`);
        // Don't throw error to avoid failing the main request
        return null;
    }
}

// Initialize Secret Manager client with ADC
const secretManagerClient = new SecretManagerServiceClient();

// Initialize variable for PredictionServiceClient (will be set later)
let predictionClient = null;

// Get credentials from Secret Manager
async function getCredentials() {
    try {
        const secretName = `projects/${CONFIG.projectId}/secrets/KEY/versions/latest`;
        console.log('Getting credentials from Secret Manager:', secretName);
        const [version] = await secretManagerClient.accessSecretVersion({ name: secretName });
        return JSON.parse(version.payload.data.toString());
    } catch (error) {
        console.error('Failed to get credentials from Secret Manager:', error);
        throw error;
    }
}

// Initialize Vertex AI client
async function initializeVertexAI() {
    try {
        console.log('Getting credentials from Secret Manager...');
        const credentials = await getCredentials();

        console.log('Initializing Vertex AI client with Secret Manager credentials');
        const apiEndpoint = process.env.VERTEX_AI_ENDPOINT || 
                          `${CONFIG.location}-aiplatform.googleapis.com`;
        
        console.log(`Using Vertex AI API endpoint: ${apiEndpoint}`);
        console.log(`Configured endpoints - Hepatic: ${CONFIG.endpointIds.hepatic}, Portal: ${CONFIG.endpointIds.portal}, Renal: ${CONFIG.endpointIds.renal}`);
        
        return new v1.PredictionServiceClient({
            apiEndpoint: apiEndpoint,
            credentials: credentials,
            // Add timeout to prevent hanging calls
            timeout: 120000 // 2 minutes timeout
        });
    } catch (error) {
        console.error('Failed to initialize Vertex AI client:', error);
        console.error('Error details:', error); // Log the entire error object for more details
        throw error;
    }
}

///////////////////////////////////////////////////////////////////////////////
// 2) Express App Setup
///////////////////////////////////////////////////////////////////////////////
const app = express();
const DEFAULT_PORT = process.env.PORT || 3002;
let PORT = DEFAULT_PORT;


app.use(cors({
    origin: true,
    methods: ['GET', 'POST'],
    allowedHeaders: ['Content-Type', 'Authorization']
}));

// Increase JSON and URL-encoded payload limits
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// Log requests
app.use(async (req, res, next) => {
    console.log(`[${new Date().toISOString()}] Requesting: ${req.url}`);
    await fs.appendFile('server.log', `Requesting: ${req.url}\n`);
    next();
});

// Add error handling middleware
app.use((err, req, res, next) => {
    console.error('Server error:', err);
    res.status(500).json({
        error: 'Internal Server Error',
        message: err.message,
        timestamp: new Date().toISOString()
    });
});

// Serve static files with proper caching headers
app.use(express.static(path.join(__dirname, 'public'), {
    maxAge: '1h',
    setHeaders: (res, path) => {
        if (path.endsWith('.html')) {
            // Don't cache HTML files
            res.setHeader('Cache-Control', 'no-cache');
        }
    }
}));

///////////////////////////////////////////////////////////////////////////////
// 3) Authentication Endpoint
///////////////////////////////////////////////////////////////////////////////
app.post('/auth/token', async (req, res) => {
  try {
    await initializeVertexAI(); // Initialize Vertex AI client to verify credentials
    res.json({ status: 'ok', timestamp: new Date().toISOString() });
  } catch (error) {
    console.error('Auth error:', error);
    res.status(500).json({ error: 'Authentication failed', message: error.message, timestamp: new Date().toISOString() });
  }
});



///////////////////////////////////////////////////////////////////////////////
// 4) Health Check Endpoint
///////////////////////////////////////////////////////////////////////////////
app.get('/api/health', async (req, res) => {
    console.log('Health check requested');
    
    try {
        // Basic health check
        const healthData = {
            status: 'ok',
            timestamp: new Date().toISOString(),
            serverInfo: {
                projectId: CONFIG.projectId,
                location: CONFIG.location,
                endpointConfig: CONFIG.endpointIds,
                lastUpdated: CONFIG.lastUpdated,
                bucketName: CONFIG.bucketName
            }
        };
        
        // Check if we should do a detailed health check
        const detailed = req.query.detailed === 'true';
        
        if (detailed) {
            console.log('Performing detailed health check including Vertex AI connectivity');
            
            // Test Secret Manager access
            try {
                const credentials = await getCredentials();
                healthData.secretManager = { status: 'ok' };
            } catch (secretError) {
                console.error('Secret Manager error during health check:', secretError);
                healthData.secretManager = { 
                    status: 'error', 
                    message: secretError.message 
                };
            }
            
            // Test Cloud Storage access
            try {
                const [bucketExists] = await bucket.exists();
                healthData.storage = { 
                    status: bucketExists ? 'ok' : 'error',
                    bucketExists: bucketExists
                };
            } catch (storageError) {
                console.error('Cloud Storage error during health check:', storageError);
                healthData.storage = { 
                    status: 'error', 
                    message: storageError.message 
                };
            }
            
            // Test Vertex AI endpoints
            healthData.endpoints = {};
            
            // Get credentials for Vertex AI
            try {
                const credentials = await getCredentials();
                const auth = new GoogleAuth({
                    credentials: credentials,
                    scopes: ['https://www.googleapis.com/auth/cloud-platform']
                });
                
                const client = await auth.getClient();
                const token = await client.getAccessToken();
                
                // Test each endpoint
                for (const [veinType, endpointId] of Object.entries(CONFIG.endpointIds)) {
                    try {
                        console.log(`Testing ${veinType} endpoint (ID: ${endpointId}) during health check`);
                        
                        // Construct the endpoint URL
                        const baseApiUrl = `https://${CONFIG.location}-aiplatform.googleapis.com/v1`;
                        const endpointPath = `projects/${CONFIG.projectNumber}/locations/${CONFIG.location}/endpoints/${endpointId}`;
                        const url = `${baseApiUrl}/${endpointPath}`;
                        
                        // Make a GET request to check if the endpoint exists
                        const response = await fetch(url, {
                            method: 'GET',
                            headers: {
                                'Authorization': `Bearer ${token.token}`
                            }
                        });
                        
                        if (response.ok) {
                            const endpointData = await response.json();
                            healthData.endpoints[veinType] = {
                                status: 'ok',
                                endpointId: endpointId,
                                displayName: endpointData.displayName,
                                deployedModels: endpointData.deployedModels ? 
                                    endpointData.deployedModels.map(m => ({
                                        id: m.id,
                                        status: m.status
                                    })) : []
                            };
                        } else {
                            const errorText = await response.text();
                            healthData.endpoints[veinType] = {
                                status: 'error',
                                statusCode: response.status,
                                message: errorText
                            };
                        }
                    } catch (endpointError) {
                        console.error(`Error checking ${veinType} endpoint:`, endpointError);
                        healthData.endpoints[veinType] = {
                            status: 'error',
                            message: endpointError.message
                        };
                    }
                }
            } catch (authError) {
                console.error('Authentication error during health check:', authError);
                healthData.auth = {
                    status: 'error',
                    message: authError.message
                };
            }
        }
        
        res.json(healthData);
    } catch (error) {
        console.error('Health check error:', error);
        res.status(500).json({
            status: 'error',
            message: error.message,
            timestamp: new Date().toISOString()
        });
    }
});

///////////////////////////////////////////////////////////////////////////////
// 5) Image Upload and Prediction Endpoint
///////////////////////////////////////////////////////////////////////////////
app.post('/api/predict', upload.single('image'), async (req, res) => {
    console.log('Received prediction request');
    const startTime = Date.now();
    let imageInfo = null;
    
    try {
        // Get vein type from request
        const veinType = (req.body.metadata?.veinType || req.body.veinType || 'hepatic').toLowerCase();
        console.log(`Prediction request for ${veinType} vein`);
        
        // Check if we should bypass the on-demand service
        const bypassOnDemand = req.query.direct === 'true' || 
                              req.body.metadata?.direct === true || 
                              req.body.direct === true || 
                              process.env.BYPASS_ONDEMAND === 'true';
        
        if (bypassOnDemand) {
            console.log('Bypassing on-demand service as requested');
        }
        
        // Check valid vein type
        if (!['hepatic', 'portal', 'renal'].includes(veinType)) {
            return res.status(400).json({ 
                error: `Invalid vein type: ${veinType}. Must be one of: hepatic, portal, renal` 
            });
        }
        
        // Get image data from request
        let imageData;
        let imageType = req.body.metadata?.imageType || req.body.imageType || 'image/jpeg';
        
        if (req.file) {
            // If image was uploaded as a file
            console.log('Processing uploaded file for prediction');
            const imageBuffer = req.file.buffer;
            imageData = imageBuffer.toString('base64');
        } else if (req.body.instances && req.body.instances[0] && req.body.instances[0].content) {
            // If image was sent in Vertex AI format
            console.log('Processing image from instances array');
            imageData = req.body.instances[0].content;
        } else if (req.body.content) {
            // If image was sent directly in content field
            console.log('Processing image from direct content field');
            imageData = req.body.content;
        } else {
            return res.status(400).json({ error: 'No image data provided' });
        }
        
        // Prepare image for prediction
        const preparedImage = await prepareImageForPrediction(imageData, imageType);
        
        if (!preparedImage || !preparedImage.content) {
            return res.status(400).json({ error: 'Provided image is not valid' });
        }
        
        console.log(`Image prepared for prediction, mime type: ${preparedImage.mimeType}`);
        
        // Store image if enabled (both raw and processed versions for debugging)
        if (CONFIG.storeImages) {
            try {
                imageInfo = await uploadImage(
                    `data:${preparedImage.mimeType};base64,${preparedImage.content}`, 
                    veinType
                );
                console.log(`Image stored with ID: ${imageInfo.id}`);
            } catch (storageError) {
                console.error('Error storing image:', storageError);
                // Continue despite storage error
            }
        }
        
        // Create the correctly formatted instances array
        const instances = [
            {
                content: preparedImage.content
            }
        ];
        
        // Get parameters from request or use defaults
        const parameters = req.body.parameters || {
            confidenceThreshold: 0.0,
            maxPredictions: 5
        };
        
        // First try the on-demand service
        console.log('Calling on-demand service for prediction');
        console.log(`Using on-demand service URL: ${CONFIG.onDemandEndpointService}`);
        
        // Log request diagnostics
        await logDiagnostics('REQUEST', { 
            veinType, 
            imageType: preparedImage.mimeType,
            hasInstances: true,
            instanceCount: instances.length,
            parameters
        }, null, veinType);
        
        // Make the call to the on-demand service
        try {
            // Get credentials and token 
            const credentials = await getCredentials();
            const token = credentials.access_token || credentials;
            
            // Add diagnostic logging for on-demand request
            const onDemandPayload = {
                instances,
                parameters,
                metadata: {
                    veinType,
                    imageType: preparedImage.mimeType,
                    timestamp: Date.now()
                }
            };
            
            await logDiagnostics('ONDEMAND_REQUEST', onDemandPayload, null, veinType);
            
            // Call the on-demand service
            const result = await makeApiCallWithRetry(
                CONFIG.onDemandEndpointService,
                onDemandPayload,
                token,
                veinType
            );

            // Add diagnostic logging for on-demand response
            await logDiagnostics('ONDEMAND_RESPONSE', result, null, veinType);
            
            // Store prediction results if we have image info
            if (imageInfo && result.predictions && result.predictions.length > 0) {
                try {
                    await storePredictionResults(
                        imageInfo,
                        {
                            displayNames: result.predictions[0].displayNames || [],
                            confidences: result.predictions[0].confidences || [],
                            modelId: result.modelId || null
                        },
                        veinType
                    );
                } catch (resultStorageError) {
                    console.error('Error storing prediction results:', resultStorageError);
                }
            }
            
            // Check if we got empty predictions
            const displayNames = result.predictions?.[0]?.displayNames || [];
            const confidences = result.predictions?.[0]?.confidences || [];
            
            console.log(`Received ${displayNames.length} displayNames and ${confidences.length} confidences`);
            
            // If we got valid predictions, return them
            if (displayNames.length > 0 && confidences.length > 0) {
                return res.json({
                    displayNames: displayNames,
                    confidences: confidences,
                    modelId: result.modelId || null,
                    method: 'ondemand',
                    timestamp: new Date().toISOString(),
                    storage: imageInfo ? {
                        stored: true,
                        imageUrl: imageInfo.url,
                        resultsPath: imageInfo.id
                    } : null
                });
            }
            
            // If we got empty predictions, try direct Vertex AI call
            console.log('On-demand service returned empty predictions, trying direct Vertex AI call');
        } catch (onDemandError) {
            console.error('On-demand service error:', onDemandError);
            
            // Add diagnostic logging for on-demand error
            await logDiagnostics('ONDEMAND_ERROR', null, onDemandError, veinType);
            
            // Log more details about the error
            console.error('Error type:', onDemandError.constructor.name);
            if (onDemandError.code) {
                console.error('Error code:', onDemandError.code);
            }
            if (onDemandError.response) {
                console.error('Response status:', onDemandError.response.status);
                console.error('Response text:', await onDemandError.response.text());
            }
        }
        
        // Try direct vertex AI call as a fallback
        console.log('Falling back to direct Vertex AI call');
        
        try {
            // Initialize Vertex AI client if not already done
                    if (!predictionClient) {
                        predictionClient = await initializeVertexAI();
                    }
                    
                    const endpointId = CONFIG.endpointIds[veinType];
                    const endpointPath = `projects/${CONFIG.projectNumber}/locations/${CONFIG.location}/endpoints/${endpointId}`;
                    
                    console.log(`Sending direct prediction request to endpoint: ${endpointPath}`);
                    
                    // Create the request object for direct Vertex AI call
                    const directRequest = {
                        endpoint: endpointPath,
                        instances: instances,
                        parameters: parameters || {
                            confidenceThreshold: 0.0,
                            maxPredictions: 5
                        }
                    };
                    
                    // Add diagnostic logging for direct API request
                    await logDiagnostics('DIRECT_REQUEST', directRequest, null, veinType);
                    
                    const [directResponse] = await predictionClient.predict(directRequest);
                    
                    // Add diagnostic logging for direct API response
                    await logDiagnostics('DIRECT_RESPONSE', directResponse, null, veinType);
                    
                    // Schedule endpoint shutdown after the direct API call
                    scheduleEndpointShutdown(veinType);
                    
                    // If direct call also fails to provide predictions, return error instead of using mock
                    if (!directResponse.predictions || 
                        directResponse.predictions.length === 0 || 
                        !directResponse.predictions[0].displayNames || 
                        directResponse.predictions[0].displayNames.length === 0) {
                        
                        console.log('Direct call also returned empty predictions, returning error');
                        
                        // Log the empty prediction response
                        await logDiagnostics('EMPTY_PREDICTION_ERROR', directResponse, null, veinType);
                        
                        // Return an error response to the client
                        return res.status(404).json({
                            error: 'No predictions available from AI model',
                            details: 'Both on-demand service and direct calls returned empty predictions',
                            veinType: veinType,
                            timestamp: new Date().toISOString()
                        });
                    }
                    
                    // Return the direct prediction response
                    return res.json({
                        displayNames: directResponse.predictions[0].displayNames || [],
                        confidences: directResponse.predictions[0].confidences || [],
                        modelId: directResponse.deployedModelId || null,
                        method: 'direct', // Indicate this was a direct call
                        timestamp: new Date().toISOString()
                    });
                } catch (directError) {
                    console.error('Direct Vertex AI call failed:', directError);
                    
                    // Add diagnostic logging for direct API error
                    await logDiagnostics('DIRECT_ERROR', null, directError, veinType);
                    
                    // Schedule endpoint shutdown even after error
                    scheduleEndpointShutdown(veinType);
                    
                    // Return error instead of using mock predictions
                    console.log('Returning prediction error after direct call failed');
                    
                    return res.status(500).json({
                        error: 'Prediction service unavailable',
                        details: directError.message || 'Error during direct Vertex AI call',
                        veinType: veinType,
                        timestamp: new Date().toISOString()
                    });
                }
    } catch (error) {
            console.error('Prediction error:', error);
            
            // Add diagnostic logging for error
            await logDiagnostics('PREDICTION_ERROR', null, error, veinType);
            
            // Try direct vertex AI call as a fallback
            console.log('Falling back to direct Vertex AI call');
            
            try {
                // Initialize Vertex AI client if not already done
                if (!predictionClient) {
                    predictionClient = await initializeVertexAI();
                }
                
                const endpointId = CONFIG.endpointIds[veinType];
                const endpointPath = `projects/${CONFIG.projectNumber}/locations/${CONFIG.location}/endpoints/${endpointId}`;
                
                console.log(`Sending direct prediction request to endpoint: ${endpointPath}`);
                
                // Create the request object for direct Vertex AI call
                const directRequest = {
                    endpoint: endpointPath,
                    instances: instances,
                    parameters: parameters || {
                        confidenceThreshold: 0.0,
                        maxPredictions: 5
                    }
                };
                
                // Add diagnostic logging for direct API request
                await logDiagnostics('DIRECT_REQUEST', directRequest, null, veinType);
                
                const [directResponse] = await predictionClient.predict(directRequest);
                
                // Add diagnostic logging for direct API response
                await logDiagnostics('DIRECT_RESPONSE', directResponse, null, veinType);
                
                // Store results if we have image info
                if (imageInfo && directResponse.predictions && directResponse.predictions.length > 0) {
                    const directPrediction = directResponse.predictions[0];
                    
                    try {
                        await storePredictionResults(
                            imageInfo,
                            {
                                displayNames: directPrediction.displayNames || [],
                                confidences: directPrediction.confidences || [],
                                modelId: directResponse.deployedModelId || null
                            },
                            veinType
                        );
                    } catch (resultStorageError) {
                        console.error('Error storing direct prediction results:', resultStorageError);
                    }
                }
                
                // Schedule endpoint shutdown after the direct API call
                scheduleEndpointShutdown(veinType);
                
                // Check if we got valid predictions, return error if not
                if (!directResponse.predictions || 
                    directResponse.predictions.length === 0 || 
                    !directResponse.predictions[0].displayNames || 
                    directResponse.predictions[0].displayNames.length === 0) {
                    
                    console.log('Direct call returned empty predictions, returning error');
                    
                    // Log the error
                    await logDiagnostics('EMPTY_PREDICTION_ERROR', directResponse, null, veinType);
                    
                    // Return an error response to the client
                    return res.status(404).json({
                        error: 'No predictions available from AI model',
                        details: 'Direct Vertex AI call returned empty predictions',
                        veinType: veinType,
                        timestamp: new Date().toISOString()
                    });
                }
                
                // Return the prediction response
                return res.json({
                    displayNames: directResponse.predictions[0].displayNames || [],
                    confidences: directResponse.predictions[0].confidences || [],
                    modelId: directResponse.deployedModelId || null,
                    method: 'direct', // Indicate this was a direct call
                    timestamp: new Date().toISOString(),
                    storage: imageInfo ? {
                        stored: true,
                        imageUrl: imageInfo.url,
                        resultsPath: imageInfo.id
                    } : null
                });
                
            } catch (directError) {
                console.error('Direct Vertex AI call failed:', directError);
                
                // Add diagnostic logging for direct API error
                await logDiagnostics('DIRECT_ERROR', null, directError, veinType);
                
                // Schedule endpoint shutdown even after error
                scheduleEndpointShutdown(veinType);
                
                // Return error instead of using mock predictions
                console.log('Returning prediction error after both services failed');
                
                return res.status(503).json({
                    error: 'Prediction service unavailable',
                    details: 'Direct Vertex AI call failed',
                    message: directError.message,
                    veinType: veinType,
                    timestamp: new Date().toISOString()
                });
            }
        }
        
    } catch (error) {
        console.error('Prediction error:', error);
        
        // Add error diagnostic logging
        await logDiagnostics('ERROR', null, error);
        
        // Return the error to the client
        return res.status(500).json({ 
            error: error.message || 'An unexpected error occurred during prediction',
            timestamp: new Date().toISOString()
        });
    } finally {
        const endTime = Date.now();
        const duration = endTime - startTime;
        console.log(`Prediction request completed in ${duration}ms`);
    }
});

///////////////////////////////////////////////////////////////////////////////
// 6) Endpoint Prewarming
///////////////////////////////////////////////////////////////////////////////
app.post('/api/preload-endpoint', async (req, res) => {
    try {
        const { type } = req.body;
        
        if (!type || !['hepatic', 'portal', 'renal'].includes(type)) {
            return res.status(400).json({ 
                status: 'error',
                message: 'Invalid or missing vein type. Must be one of: hepatic, portal, renal',
                timestamp: new Date().toISOString()
            });
        }
        
        console.log(`Prewarming ${type} endpoint...`);
        
        // Get the endpoint ID for the specified vein type
        const endpointId = CONFIG.endpointIds[type];
        
        // We don't actually need to make a full prediction call to warm up the endpoint
        // Just verifying we can connect to it is enough to start the warm-up process
        try {
            // Get credentials from Secret Manager
            const credentials = await getCredentials();
            
            // Get an access token using the credentials
            const auth = new GoogleAuth({
                credentials: credentials,
                scopes: ['https://www.googleapis.com/auth/cloud-platform']
            });
            
            const client = await auth.getClient();
            const token = await client.getAccessToken();
            
            // Construct the endpoint URL
            const baseApiUrl = `https://${CONFIG.location}-aiplatform.googleapis.com/v1`;
            const endpointPath = `projects/${CONFIG.projectNumber}/locations/${CONFIG.location}/endpoints/${endpointId}`;
            const url = `${baseApiUrl}/${endpointPath}`;
            
            // Make a GET request to check if the endpoint exists
            const response = await fetch(url, {
                method: 'GET',
                headers: {
                    'Authorization': `Bearer ${token.token}`
                }
            });
            
            if (response.ok) {
                return res.json({
                    status: 'warming',
                    message: `${type} endpoint warming initiated`,
                    endpointId: endpointId,
                    timestamp: new Date().toISOString()
                });
            } else {
                const errorText = await response.text();
                throw new Error(`Endpoint check failed with status ${response.status}: ${errorText}`);
            }
        } catch (error) {
            console.error(`Error prewarming ${type} endpoint:`, error);
            return res.status(500).json({
                status: 'error',
                message: `Failed to prewarm ${type} endpoint: ${error.message}`,
                timestamp: new Date().toISOString()
            });
        }
    } catch (error) {
        console.error('Endpoint prewarming error:', error);
        res.status(500).json({ 
            status: 'error',
            message: `Endpoint prewarming failed: ${error.message}`,
            timestamp: new Date().toISOString()
        });
    }
});

///////////////////////////////////////////////////////////////////////////////
// 7) Direct Prediction Endpoint (Bypasses On-Demand Service)
///////////////////////////////////////////////////////////////////////////////
app.post('/api/predict/direct/:vein_type', upload.single('image'), async (req, res) => {
    console.log('Received direct prediction request');
    const startTime = Date.now();
    let imageInfo = null;
    
    try {
        // Get vein type from URL parameter
        const veinType = req.params.vein_type.toLowerCase();
        console.log(`Direct prediction request for ${veinType} vein`);
        
        // Check valid vein type
        if (!['hepatic', 'portal', 'renal'].includes(veinType)) {
            return res.status(400).json({ 
                error: `Invalid vein type: ${veinType}. Must be one of: hepatic, portal, renal` 
            });
        }
        
        // Get image data from request
        let imageData;
        let imageType = req.body.metadata?.imageType || req.body.imageType || 'image/jpeg';
        
        if (req.file) {
            // If image was uploaded as a file
            console.log('Processing uploaded file for prediction');
            const imageBuffer = req.file.buffer;
            imageData = imageBuffer.toString('base64');
        } else if (req.body.instances && req.body.instances[0] && req.body.instances[0].content) {
            // If image was sent in Vertex AI format
            console.log('Processing image from instances array');
            imageData = req.body.instances[0].content;
        } else if (req.body.content) {
            // If image was sent directly in content field
            console.log('Processing image from direct content field');
            imageData = req.body.content;
        } else {
            return res.status(400).json({ error: 'No image data provided' });
        }
        
        // Prepare image for prediction
        const preparedImage = await prepareImageForPrediction(imageData, imageType);
        
        if (!preparedImage || !preparedImage.content) {
            return res.status(400).json({ error: 'Provided image is not valid' });
        }
        
        console.log(`Image prepared for prediction, mime type: ${preparedImage.mimeType}`);
        
        // Create the correctly formatted instances array
        const instances = [
            {
                content: preparedImage.content
            }
        ];
        
        // Get parameters from request or use defaults
        const parameters = req.body.parameters || {
            confidenceThreshold: 0.0,
            maxPredictions: 5
        };
        
        // Initialize Vertex AI client if not already done
        if (!predictionClient) {
            predictionClient = await initializeVertexAI();
        }
        
        const endpointId = CONFIG.endpointIds[veinType];
        const endpointPath = `projects/${CONFIG.projectNumber}/locations/${CONFIG.location}/endpoints/${endpointId}`;
        
        console.log(`Sending direct prediction request to endpoint: ${endpointPath}`);
        
        // Create the request object for direct Vertex AI call
        const directRequest = {
            endpoint: endpointPath,
            instances: instances,
            parameters: parameters
        };
        
        // Add diagnostic logging for direct API request
        await logDiagnostics('DIRECT_REQUEST', directRequest, null, veinType);
        
        try {
            const [directResponse] = await predictionClient.predict(directRequest);
            
            // Add diagnostic logging for direct API response
            await logDiagnostics('DIRECT_RESPONSE', directResponse, null, veinType);
            
            // Check if we got valid predictions, return error if not
            if (!directResponse.predictions || 
                directResponse.predictions.length === 0 || 
                !directResponse.predictions[0].displayNames || 
                directResponse.predictions[0].displayNames.length === 0) {
                
                console.log('Direct call returned empty predictions, returning error');
                
                // Log the error
                await logDiagnostics('EMPTY_PREDICTION_ERROR', directResponse, null, veinType);
                
                // Return an error response to the client
                return res.status(404).json({
                    error: 'No predictions available from AI model',
                    details: 'Direct Vertex AI call returned empty predictions',
                    veinType: veinType,
                    timestamp: new Date().toISOString()
                });
            }
            
            // Return the prediction response
            return res.json({
                displayNames: directResponse.predictions[0].displayNames || [],
                confidences: directResponse.predictions[0].confidences || [],
                modelId: directResponse.deployedModelId || null,
                method: 'direct', // Indicate this was a direct call
                timestamp: new Date().toISOString()
            });
        } catch (directError) {
            console.error('Direct Vertex AI call failed:', directError);
            
            // Add diagnostic logging for direct API error
            await logDiagnostics('DIRECT_ERROR', null, directError, veinType);
            
            // Return error
            return res.status(500).json({
                error: 'Prediction service unavailable',
                details: directError.message || 'Error during direct Vertex AI call',
                veinType: veinType,
                timestamp: new Date().toISOString()
            });
        }
    } catch (error) {
        console.error('Direct prediction error:', error);
        
        // Add error diagnostic logging
        await logDiagnostics('ERROR', null, error);
        
        // Return the error to the client
        return res.status(500).json({ 
            error: error.message || 'An unexpected error occurred during prediction',
            timestamp: new Date().toISOString()
        });
    } finally {
        const endTime = Date.now();
        const duration = endTime - startTime;
        console.log(`Direct prediction request completed in ${duration}ms`);
    }
});

///////////////////////////////////////////////////////////////////////////////
// 8) Test Endpoint for Connectivity Check
///////////////////////////////////////////////////////////////////////////////
app.post('/api/test-endpoint', async (req, res) => {
    try {
        const { metadata } = req.body;
        
        // Extract vein type from request metadata
        const veinType = metadata?.veinType || 'hepatic';
        console.log(`Testing endpoint connection for vein type: ${veinType}`);
        
        // Select the appropriate endpoint ID based on vein type
        const endpointId = CONFIG.endpointIds[veinType] || CONFIG.endpointIds.hepatic;
        
        // Get the expected endpoint ID if provided
        const expectedId = metadata?.expectedIds?.[veinType];
        
        // Log if there's a mismatch
        if (expectedId && expectedId !== endpointId) {
            console.warn(`Warning: Expected endpoint ID for ${veinType} (${expectedId}) differs from configured ID (${endpointId})`);
        }
        
        // Get credentials from Secret Manager
        const credentials = await getCredentials();
        
        // Get an access token using the credentials
        const auth = new GoogleAuth({
            credentials: credentials,
            scopes: ['https://www.googleapis.com/auth/cloud-platform']
        });
        
        const client = await auth.getClient();
        
        // Just get the token - this verifies auth is working
        await client.getAccessToken();
        
        // Return success without actually calling the model endpoint
        // This verifies our auth works and we have a valid endpoint ID
        res.json({
            status: 'ok',
            veinType: veinType,
            endpointId: endpointId,
            expectedId: expectedId,
            match: !expectedId || expectedId === endpointId,
            message: `Successfully verified connection for ${veinType} endpoint`,
            timestamp: new Date().toISOString()
        });
    } catch (error) {
        console.error(`Endpoint test error for ${req.body.metadata?.veinType || 'unknown'}:`, error);
        res.status(500).json({ 
            error: 'Endpoint test failed', 
            message: error.message,
            veinType: req.body.metadata?.veinType || 'unknown',
            timestamp: new Date().toISOString()
        });
    }
});

// Here's a simple version of the health endpoint that doesn't require any Google Cloud services
// This will work even when we can't connect to Google Cloud
app.get('/api/local-health', (req, res) => {
    res.json({
        status: 'ok',
        timestamp: new Date().toISOString(),
        message: 'Local health check endpoint is working',
        endpointConfig: CONFIG.endpointIds
    });
});

// Fallback route handler for SPA
app.get('*', (req, res) => {
    // Log the 404 request
    console.log(`404 request for ${req.originalUrl}`);
    res.status(404).send('Route not found');
});

// Start the server
PORT = process.env.PORT || 3003;
app.listen(PORT, () => {
    console.log(`Server running on port ${PORT}`);
    console.log(`Configuration: ${JSON.stringify(CONFIG, null, 2)}`);
});

// Function to prepare image for prediction
async function prepareImageForPrediction(imageContent, imageType = 'image/jpeg') {
    console.log(`Preparing image for prediction, type: ${imageType}`);
    
    try {
        // Log the type and first few characters of the content for debugging
        console.log(`Image content type: ${typeof imageContent}`);
        if (typeof imageContent === 'string') {
            console.log(`Image content starts with: ${imageContent.substring(0, 20)}...`);
            console.log(`Image content length: ${imageContent.length} characters`);
            
            // Check if it's a valid base64 string
            const isBase64 = /^[A-Za-z0-9+/=]+$/.test(imageContent.replace(/\s/g, ''));
            console.log(`Is valid base64 (without data URL): ${isBase64}`);
        } else if (Buffer.isBuffer(imageContent)) {
            console.log(`Image content is a Buffer of length: ${imageContent.length} bytes`);
        } else {
            console.log(`Image content is of unexpected type: ${typeof imageContent}`);
        }
        
        // Check if the imageContent is already a base64 string without data URL prefix
        if (!/^data:/.test(imageContent) && /^[A-Za-z0-9+/=]+$/.test(imageContent.replace(/\s/g, ''))) {
            console.log('Image content appears to be already in base64 format without prefix');
            // Remove any whitespace that might be in the base64 string
            const cleanBase64 = imageContent.replace(/\s/g, '');
            return {
                content: cleanBase64,
                mimeType: imageType
            };
        }
        
        // Check if the imageContent is a data URL (starts with data:)
        if (imageContent.startsWith('data:')) {
            console.log('Image content is a data URL, extracting base64 content and mime type');
            const parts = imageContent.split(',');
            if (parts.length !== 2) {
                throw new Error('Invalid base64 data format');
            }
            
            const base64Content = parts[1];
            const mimeTypeMatch = parts[0].match(/:(.*?);/);
            if (!mimeTypeMatch) {
                console.log('Could not determine image MIME type from data URL, using provided type');
                return {
                    content: base64Content,
                    mimeType: imageType
                };
            }
            
            const mimeType = mimeTypeMatch[1];
            console.log(`Successfully extracted base64 content and MIME type: ${mimeType}`);
            return {
                content: base64Content,
                mimeType: mimeType
            };
        }
        
        // If we're dealing with a file path or buffer
        if (typeof imageContent === 'string' && !imageContent.startsWith('data:')) {
            if (fs.existsSync(imageContent)) {
                console.log(`Reading image from file path: ${imageContent}`);
                const imageBuffer = await fs.readFile(imageContent);
                const base64Content = imageBuffer.toString('base64');
                return {
                    content: base64Content,
                    mimeType: imageType
                };
            } else {
                console.log('Image content is not a file path, treating as raw base64');
                // Clean up any whitespace in the base64 string
                const cleanBase64 = imageContent.replace(/\s/g, '');
                return {
                    content: cleanBase64,
                    mimeType: imageType
                };
            }
        }
        
        // If we have a buffer
        if (Buffer.isBuffer(imageContent)) {
            console.log('Image content is a buffer, converting to base64');
            const base64Content = imageContent.toString('base64');
            return {
                content: base64Content,
                mimeType: imageType
            };
        }
        
        // Fallback - assume it's already properly formatted
        console.log('Using image content as-is with provided MIME type');
        if (typeof imageContent === 'string') {
            // Clean up any whitespace in the base64 string
            const cleanBase64 = imageContent.replace(/\s/g, '');
            return {
                content: cleanBase64,
                mimeType: imageType
            };
        }
        
        return {
            content: imageContent,
            mimeType: imageType
        };
    } catch (error) {
        console.error('Error preparing image for prediction:', error);
        throw new Error('Failed to prepare image for prediction: ' + error.message);
    }
}

// Function to log diagnostics
async function logDiagnostics(eventType, data, error, veinType = 'unknown') {
    try {
        console.log(`[DIAGNOSTIC] ${eventType} - ${veinType}`);
        
        if (data) {
            // Avoid logging large image data
            const sanitizedData = { ...data };
            if (sanitizedData.instances) {
                sanitizedData.instances = sanitizedData.instances.map(instance => {
                    if (instance.content) {
                        if (typeof instance.content === 'string') {
                            return { 
                                ...instance, 
                                content: `[BASE64 DATA - ${instance.content.length} chars]`
                            };
                        } else if (instance.content.b64) {
                            return {
                                ...instance,
                                content: {
                                    b64: `[BASE64 DATA - ${instance.content.b64.length} chars]`
                                }
                            };
                        }
                    }
                    return instance;
                });
            }
            
            console.log(`[DIAGNOSTIC] Data: ${JSON.stringify(sanitizedData, null, 2)}`);
        }
        
        if (error) {
            console.error(`[DIAGNOSTIC] Error: ${error.message}`);
            console.error(`[DIAGNOSTIC] Stack: ${error.stack}`);
            
            // Log more detailed error information for specific error types
            if (error.code) {
                console.error(`[DIAGNOSTIC] Error Code: ${error.code}`);
            }
            if (error.details) {
                console.error(`[DIAGNOSTIC] Error Details: ${error.details}`);
            }
            if (error.metadata) {
                console.error(`[DIAGNOSTIC] Error Metadata:`, error.metadata);
            }
        }
        
        // Log to file for persistent diagnostics
        try {
            await fs.appendFile('server_debug.log', 
                `[${new Date().toISOString()}] [${eventType}] [${veinType}] ` + 
                (data ? `Data: ${JSON.stringify(sanitizedData, null, 2)} ` : '') +
                (error ? `Error: ${error.message} ` : '') + 
                '\n'
            );
        } catch (fileError) {
            console.error('Error writing to debug log file:', fileError);
        }
        
        // In a production environment, you might want to store these diagnostics
        // in a database or log aggregation service
    } catch (logError) {
        console.error('Error logging diagnostics:', logError);
    }
}

// Function to generate mock predictions
async function generateMockPredictions(veinType = 'hepatic') {
    console.log(`Generating mock predictions for ${veinType} vein`);
    
    // Define mock predictions for each vein type
    const mockPredictions = {
        hepatic: [
            { class: "Normal", confidence: 0.85 },
            { class: "Mild Congestion", confidence: 0.10 },
            { class: "Moderate Congestion", confidence: 0.03 },
            { class: "Severe Congestion", confidence: 0.02 }
        ],
        portal: [
            { class: "Normal", confidence: 0.75 },
            { class: "Mild Congestion", confidence: 0.15 },
            { class: "Moderate Congestion", confidence: 0.07 },
            { class: "Severe Congestion", confidence: 0.03 }
        ],
        renal: [
            { class: "Normal", confidence: 0.80 },
            { class: "Mild Congestion", confidence: 0.12 },
            { class: "Moderate Congestion", confidence: 0.05 },
            { class: "Severe Congestion", confidence: 0.03 }
        ]
    };
    
    // Use the appropriate mock predictions or fall back to hepatic if vein type not found
    const predictions = mockPredictions[veinType] || mockPredictions.hepatic;
    
    // Add some randomness to make it look more realistic
    const randomizedPredictions = predictions.map(pred => {
        // Add/subtract up to 10% randomly
        const randomFactor = 1 + (Math.random() * 0.2 - 0.1);
        return {
            class: pred.class,
            confidence: Math.min(0.99, Math.max(0.01, pred.confidence * randomFactor))
        };
    });
    
    // Sort by confidence
    const sortedPredictions = randomizedPredictions.sort((a, b) => b.confidence - a.confidence);
    
    // Extract display names and confidences
    const displayNames = sortedPredictions.map(p => p.class);
    const confidences = sortedPredictions.map(p => p.confidence);
    
    // Construct response
    return {
        displayNames,
        confidences,
        modelId: `mock-model-${veinType}`,
        method: 'mock',
        timestamp: new Date().toISOString()
    };
}

// Function to make API call with retry
async function makeApiCallWithRetry(url, payload, token, veinType, maxRetries = 2) {
    let retries = 0;
    let lastError = null;
    
    while (retries <= maxRetries) {
        try {
            console.log(`Making API call to ${url} (attempt ${retries + 1}/${maxRetries + 1})`);
            console.log(`Payload: ${JSON.stringify({
                ...payload,
                instances: payload.instances.map(instance => ({
                    ...instance,
                    content: instance.content ? `[BASE64 DATA - ${instance.content.length} chars]` : undefined
                }))
            }, null, 2)}`);
            
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${token}`
                },
                body: JSON.stringify(payload)
            });
            
            if (!response.ok) {
                const errorText = await response.text();
                throw new Error(`API call failed with status ${response.status}: ${errorText}`);
            }
            
            const result = await response.json();
            console.log(`API call succeeded with result: ${JSON.stringify(result, null, 2)}`);
            return result;
        } catch (error) {
            console.error(`API call attempt ${retries + 1} failed:`, error.message);
            lastError = error;
            retries++;
            
            if (retries <= maxRetries) {
                // Wait before retrying (exponential backoff)
                const delay = Math.pow(2, retries) * 1000;
                console.log(`Waiting ${delay}ms before retry...`);
                await new Promise(resolve => setTimeout(resolve, delay));
            }
        }
    }
    
    // If we get here, all retries failed
    throw lastError || new Error('API call failed after all retries');
}

// Function to schedule endpoint shutdown
function scheduleEndpointShutdown(veinType) {
    console.log(`Scheduling shutdown for ${veinType} endpoint in 5 minutes`);
    // In a production environment, you would implement actual shutdown logic here
    // For now, we'll just log that it would be scheduled
}
